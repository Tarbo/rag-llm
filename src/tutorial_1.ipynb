{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "348b1aa8",
   "metadata": {},
   "source": [
    "# Understanding GPT Parameters: Temperature, Seed, and Verbosity for RAG Applications\n",
    "\n",
    "This tutorial explores the key parameters that control how GPT models generate responses. Understanding these parameters is crucial for building effective RAG applications and controlling AI behavior.\n",
    "\n",
    "## Key Nuances to Remember:\n",
    "- **Temperature** controls creativity vs consistency\n",
    "- **Seed** enables reproducible outputs for testing\n",
    "- **Verbosity** controls response detail level ('low', 'medium', 'high')\n",
    "- **Prompt engineering** can achieve similar goals as parameters\n",
    "- Different combinations serve different use cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42ad0382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2042b810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced function to demonstrate all parameters\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\", temperature=0.1, seed=None, verbosity='medium'):\n",
    "    \"\"\"\n",
    "    Get completion with full parameter control\n",
    "    \n",
    "    Args:\n",
    "        prompt: The input prompt\n",
    "        model: Model to use\n",
    "        temperature: Controls randomness (0.0-2.0)\n",
    "        seed: For reproducible outputs\n",
    "        verbosity: Response detail level ('omit', 'low', 'medium', 'high')\n",
    "    \"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    # Build parameters dict\n",
    "    params = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature\n",
    "    }\n",
    "    \n",
    "    # Add seed if provided\n",
    "    if seed is not None:\n",
    "        params[\"seed\"] = seed\n",
    "    \n",
    "    response = openai.chat.completions.create(**params)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27da1690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing function with prompt: What is AGI in AI?\n",
      "Temperature: 0.1 (low creativity), Verbosity: medium\n",
      "Response: AGI stands for Artificial General Intelligence, which refers to a type of artificial intelligence that possesses the ability to understand, learn, and apply knowledge in a way that is similar to human intelligence. AGI is often seen as the ultimate goal of AI research, as it would be able to perform any intellectual task that a human can do.\n"
     ]
    }
   ],
   "source": [
    "# Test our function with a simple example\n",
    "test_prompt = \"What is AGI in AI?\"\n",
    "print(\"Testing function with prompt:\", test_prompt)\n",
    "print(\"Temperature: 0.1 (low creativity), Verbosity: medium\")\n",
    "response = get_completion(test_prompt, temperature=0.1, verbosity='medium')\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66cbf08",
   "metadata": {},
   "source": [
    "## 1. Understanding Temperature\n",
    "\n",
    "Temperature controls the **randomness and creativity** of responses:\n",
    "- **0.0**: Completely deterministic (same input = same output)\n",
    "- **0.1-0.3**: Low creativity, focused responses (good for facts)\n",
    "- **0.4-0.6**: Balanced creativity\n",
    "- **0.7-1.0**: High creativity, varied responses\n",
    "- **1.0+**: Very random and unpredictable (Exploration takes over)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdb05112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TEMPERATURE COMPARISON ===\n",
      "\n",
      "1. Low Temperature 0.0 - Focused, Consistent:\n",
      "Obollo in Udenu is known for its important exports of agricultural products such as yam, cassava, and palm oil. These products are grown and harvested by local farmers in the region and contribute significantly to the economy of Obollo. The yam and cassava are staple food crops that are in high demand both locally and internationally, while the palm oil is used in various industries such as food processing and cosmetics. The export of these agricultural products plays a crucial role in sustaining the livelihoods of many residents in Obollo and promoting economic growth in the region.\n",
      "Obollo in Udenu is known for its important exports of agricultural products such as yam, cassava, and palm oil. These products are grown and harvested by local farmers in the region and contribute significantly to the economy of Obollo. The yam and cassava are staple food crops that are in high demand both locally and internationally, while the palm oil is used in various industries such as food processing and cosmetics. The exports from Obollo play a crucial role in sustaining the livelihoods of many residents and promoting economic growth in the area.\n",
      "\n",
      "2. Medium Temperature 0.5 - Balanced:\n",
      "Obollo in Udenu is known for its important exports of agricultural products such as yam, cassava, and palm oil. These crops are cultivated by local farmers and contribute significantly to the economy of the region. Additionally, Obollo is also known for its production of handicrafts such as woven baskets and pottery, which are popular among tourists and contribute to the cultural heritage of the community. Overall, the exports from Obollo play a crucial role in sustaining the livelihoods of the residents and promoting economic development in the region.\n",
      "Obollo in Udenu is known for its important exports of agricultural products such as yam, cassava, and palm oil. These products are cultivated by local farmers and contribute significantly to the economy of the region. Additionally, Obollo is also known for its production of handicrafts such as woven baskets and pottery, which are highly sought after for their quality and craftsmanship. Overall, the exports from Obollo play a crucial role in supporting the livelihoods of many residents in the area.\n",
      "\n",
      "3. High Temperature 1.5 - Creative, Varied:\n",
      "Obollo in Udienu is known for its important exports of palm oil, yams, cassava, and other assorted agricultural products. The region's fertile soils contribute to the high quality and quantity of these commodities, making them key components of the local economy and vital for trade with other parts of Nigeria and abroad. Additionally, chalk production and Omployingas grass (Huaten primarily for woven ropes and craft? ews are also significant exports. Overall, the diverse range of agricultural and non-agricultural outputs from Obollo help sustain the community's economy and promote growth and development.\n",
      "The important exports from Obollo in Udenu include agricultural products such as yams, cassava, plantains, and cash crops like oil palm and cocoa. Obollo is known for its rich farmland and fertile soil, which enables farmers to grow these valuable crops in abundance. The local economy depends heavily on the export of these agricultural products, generating income and supporting the livelihoods of many residents in the area.\n"
     ]
    }
   ],
   "source": [
    "# Temperature Examples\n",
    "prompt = \"One concise paragraph description of the important exports from Obollo in udenu\"\n",
    "\n",
    "print(\"=== TEMPERATURE COMPARISON ===\")\n",
    "\n",
    "temperature = 0.0\n",
    "print(f\"\\n1. Low Temperature {temperature} - Focused, Consistent:\")\n",
    "response_low = get_completion(prompt, temperature=temperature)\n",
    "print(response_low)\n",
    "\n",
    "#repeat the same prompt with the same temperature\n",
    "response_low_repeat = get_completion(prompt, temperature=temperature)\n",
    "print(response_low_repeat)\n",
    "\n",
    "temperature = 0.5\n",
    "print(f\"\\n2. Medium Temperature {temperature} - Balanced:\")\n",
    "response_medium = get_completion(prompt, temperature=temperature)\n",
    "print(response_medium)\n",
    "\n",
    "#repeat the same prompt with the same temperature\n",
    "response_medium_repeat = get_completion(prompt, temperature=temperature)\n",
    "print(response_medium_repeat)\n",
    "\n",
    "temperature = 1.5\n",
    "print(f\"\\n3. High Temperature {temperature} - Creative, Varied:\")\n",
    "response_high = get_completion(prompt, temperature=temperature)\n",
    "print(response_high)\n",
    "\n",
    "#repeat the same prompt with the same temperature\n",
    "response_high_repeat = get_completion(prompt, temperature=temperature)\n",
    "print(response_high_repeat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216ce925",
   "metadata": {},
   "source": [
    "## 2. Understanding Seed\n",
    "\n",
    "Seed makes responses **reproducible and deterministic**:\n",
    "- **No seed**: Different responses each time (if temperature > 0)\n",
    "- **Same seed**: Identical responses (useful for testing and debugging)\n",
    "- **Different seeds**: Different but consistent responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "680d3448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SEED COMPARISON ===\n",
      "\n",
      "1. No Seed (Random each time):\n",
      "Response 1: Akatakpa Obollo is a traditional Igbo deity or deity of the Obollo community in Nigeria. It is belie...\n",
      "Response 2: Akatakpa Obollo is a traditional festival celebrated by the Obollo people in Nigeria. It is a time f...\n",
      "\n",
      "2. Same Seed (Identical responses):\n",
      "Seed 42, Run 1: Akatakpa Obollo is a traditional festival celebrated by the Obollo people in Nigeria. It is a time f...\n",
      "Seed 42, Run 2: Akatakpa Obollo is a traditional festival celebrated by the Obollo people in Nigeria. It is a time f...\n",
      "\n",
      "Are they identical? False\n"
     ]
    }
   ],
   "source": [
    "# Seed Examples\n",
    "prompt = \"Explain Akatakpa Obollo in simple terms.\"\n",
    "\n",
    "print(\"=== SEED COMPARISON ===\")\n",
    "print(\"\\n1. No Seed (Random each time):\")\n",
    "seed = None\n",
    "response1 = get_completion(prompt, temperature=0.7, seed=seed)\n",
    "print(f\"Response 1: {response1[:100]}...\")\n",
    "\n",
    "seed = 42\n",
    "response2 = get_completion(prompt, temperature=0.7, seed=seed)\n",
    "print(f\"Response 2: {response2[:100]}...\")\n",
    "\n",
    "print(\"\\n2. Same Seed (Identical responses):\")\n",
    "seed=42\n",
    "response_seed1 = get_completion(prompt, temperature=0.7, seed=seed)\n",
    "print(f\"Seed 42, Run 1: {response_seed1[:100]}...\")\n",
    "\n",
    "response_seed2 = get_completion(prompt, temperature=0.7, seed=seed)\n",
    "print(f\"Seed 42, Run 2: {response_seed2[:100]}...\")\n",
    "\n",
    "print(f\"\\nAre they identical? {response_seed1 == response_seed2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeb7f2b",
   "metadata": {},
   "source": [
    "## 3. Understanding Verbosity\n",
    "\n",
    "Verbosity controls the **detail level** of responses:\n",
    "- **'omit'** (default): Standard response detail (not yet available in gpt-3.5-turbo)\n",
    "- **'low'**: Minimal detail, concise responses (same as above)\n",
    "- **'medium'**: Moderate detail with examples (available)\n",
    "- **'high'**: Comprehensive, detailed explanations (not yet available)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a64865",
   "metadata": {},
   "source": [
    "## 4. Same Goal, Different Methods: Parameters vs Prompt Engineering\n",
    "\n",
    "Both **parameters** and **prompt engineering** can achieve similar results, but they work differently:\n",
    "\n",
    "### Parameter Control (Model-level):\n",
    "- Controls the model's internal behavior\n",
    "- Consistent across different prompts\n",
    "- Less flexible but more reliable\n",
    "\n",
    "### Prompt Engineering (Instruction-level):\n",
    "- Gives explicit instructions to the model\n",
    "- More flexible and specific\n",
    "- Can be combined with parameters\n",
    "\n",
    "### Switch the model used to GPT-5 to run this cell below since not all options are available in GPT-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e769c23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing Parameter Control vs Prompt Engineering\n",
    "base_prompt = \"Explain artificial intelligence\"\n",
    "\n",
    "print(\"=== PARAMETER CONTROL vs PROMPT ENGINEERING ===\")\n",
    "\n",
    "print(\"\\n1. Using Verbosity Parameter (Model-level control):\")\n",
    "response_param = get_completion(base_prompt, verbosity='low')\n",
    "print(f\"Parameter approach: {response_param[:150]}...\")\n",
    "\n",
    "print(\"\\n2. Using Prompt Engineering (Instruction-level control):\")\n",
    "response_prompt = get_completion(\"Explain artificial intelligence in 2 sentences\", verbosity='omit')\n",
    "print(f\"Prompt approach: {response_prompt[:150]}...\")\n",
    "\n",
    "print(\"\\n3. Combining Both Methods:\")\n",
    "response_combined = get_completion(\"Explain AI briefly\", verbosity='low')\n",
    "print(f\"Combined approach: {response_combined[:150]}...\")\n",
    "\n",
    "print(\"\\n4. Temperature + Prompt Engineering:\")\n",
    "response_creative = get_completion(\"Write a creative analogy for AI\", temperature=0.8, verbosity='medium')\n",
    "print(f\"Creative approach: {response_creative[:150]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5a7a27",
   "metadata": {},
   "source": [
    "## 5. Practical Examples for RAG Applications\n",
    "\n",
    "Here are practical parameter combinations for different RAG use cases:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "182d772d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SCENARIO 1: FACTUAL Q&A ===\n",
      "Question: Which state capital is nicknamed 042?\n",
      "Answer: Enugu\n",
      "\n",
      "=== SCENARIO 2: DOCUMENT ANALYSIS ===\n",
      "Task: Select the best candidate and analyse for 2027 elections between Obi, Atiku, and Tinubu.\n",
      "Analysis: In order to select the best candidate for the 2027 elections between Obi, Atiku, and Tinubu, we must first analyze each candidate's strengths and weaknesses.\n",
      "\n",
      "Peter Obi is a former governor of Anambra...\n",
      "\n",
      "=== SCENARIO 3: CREATIVE CONTENT ===\n",
      "Task: Write a creative summary of my life journey\n",
      "Creative Output: From humble beginnings in a small town, I embarked on a journey filled with unexpected twists and turns. Along the way, I faced challenges that tested my resilience and determination. Through hard wor...\n",
      "\n",
      "=== SCENARIO 4: TESTING WITH SEED ===\n",
      "Test prompt: Explain the concept of embeddings\n",
      "Response 1: Embeddings refer to the process of representing data in a lower-dimensional space while preserving i...\n",
      "Response 2: Embeddings refer to the process of representing data in a lower-dimensional space while preserving i...\n",
      "Identical? True\n"
     ]
    }
   ],
   "source": [
    "# RAG Application Examples\n",
    "def demonstrate_rag_scenarios():\n",
    "    \"\"\"Demonstrate different parameter combinations for RAG scenarios\"\"\"\n",
    "    \n",
    "    # Scenario 1: Factual Q&A (Low temperature)\n",
    "    print(\"=== SCENARIO 1: FACTUAL Q&A ===\")\n",
    "    factual_prompt = \"Which state capital is nicknamed 042?\"\n",
    "    response_factual = get_completion(factual_prompt, temperature=0.1)\n",
    "    print(f\"Question: {factual_prompt}\")\n",
    "    print(f\"Answer: {response_factual}\")\n",
    "    \n",
    "    # Scenario 2: Document Analysis (Medium temperature)\n",
    "    print(\"\\n=== SCENARIO 2: DOCUMENT ANALYSIS ===\")\n",
    "    analysis_prompt = \"Select the best candidate and analyse for 2027 elections between Obi, Atiku, and Tinubu.\"\n",
    "    response_analysis = get_completion(analysis_prompt, temperature=0.3)\n",
    "    print(f\"Task: {analysis_prompt}\")\n",
    "    print(f\"Analysis: {response_analysis[:200]}...\")\n",
    "    \n",
    "    # Scenario 3: Creative Content Generation (High temperature)\n",
    "    print(\"\\n=== SCENARIO 3: CREATIVE CONTENT ===\")\n",
    "    creative_prompt = \"Write a creative summary of my life journey\"\n",
    "    response_creative = get_completion(creative_prompt, temperature=0.8)\n",
    "    print(f\"Task: {creative_prompt}\")\n",
    "    print(f\"Creative Output: {response_creative[:200]}...\")\n",
    "    \n",
    "    # Scenario 4: Testing/Development (Seed for reproducibility)\n",
    "    print(\"\\n=== SCENARIO 4: TESTING WITH SEED ===\")\n",
    "    test_prompt = \"Explain the concept of embeddings\"\n",
    "    response_test1 = get_completion(test_prompt, temperature=0.5, seed=42)\n",
    "    response_test2 = get_completion(test_prompt, temperature=0.5, seed=42)\n",
    "    print(f\"Test prompt: {test_prompt}\")\n",
    "    print(f\"Response 1: {response_test1[:100]}...\")\n",
    "    print(f\"Response 2: {response_test2[:100]}...\")\n",
    "    print(f\"Identical? {response_test1 == response_test2}\")\n",
    "\n",
    "# Run the demonstration\n",
    "demonstrate_rag_scenarios()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe77ca6a",
   "metadata": {},
   "source": [
    "## 6. Parameter Selection Guide\n",
    "\n",
    "### Quick Reference for Common Use Cases:\n",
    "\n",
    "| Use Case | Temperature | Verbosity | Seed | Example |\n",
    "|----------|-------------|-----------|------|---------|\n",
    "| **Factual Q&A** | 0.1-0.3 | low | Optional | \"How old is Peter Obi?\" |\n",
    "| **Code Generation** | 0.0-0.2 | omit | Yes | Generate Python functions |\n",
    "| **Creative Writing** | 0.7-1.0 | high | No | Story generation |\n",
    "| **Document Analysis** | 0.3-0.5 | medium | Optional | Summarize documents |\n",
    "| **Testing/Debugging** | 0.1-0.5 | omit | Yes | Reproducible outputs |\n",
    "| **Conversational AI** | 0.4-0.6 | medium | No | Chat applications |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a648b4",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "Understanding GPT parameters is crucial for building effective RAG applications:\n",
    "\n",
    "### Key Takeaways:\n",
    "1. **Temperature** controls creativity vs consistency - use low values for facts, high for creativity\n",
    "2. **Seed** enables reproducible outputs - essential for testing and debugging\n",
    "3. **Verbosity** controls response detail - use 'low' for concise answers, 'high' for comprehensive explanations\n",
    "4. **Parameters and prompt engineering** work together - don't rely on just one approach\n",
    "5. **Experiment with combinations** - different use cases require different parameter settings\n",
    "\n",
    "### For RAG Applications:\n",
    "- Use **temperature=0.1-0.3** for factual retrieval\n",
    "- Use **verbosity='low'** for concise answers\n",
    "- Use **seeds** for consistent testing\n",
    "- Combine with **clear, specific prompts** for best results\n",
    "\n",
    "Remember: The right parameter combination depends on your specific use case. Start with the guidelines above, then experiment to find what works best for your application!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
